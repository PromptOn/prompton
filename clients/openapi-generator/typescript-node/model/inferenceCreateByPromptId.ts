/**
 * prompton-api
 * API for prompton - managing full lifecycle of AI chat prompts.
 *
 * The version of the OpenAPI document: 0.0.1
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

import { RequestFile } from './models';

/**
* Create inference by `prompt_id`. It can only be used if there is at least one \'Live\' status prompt version for the provided `prompt_id`. If there are multiple prompt versions in Live status it will pick one randomly. Useful for split testing prompt versions. It stores all other `prompt_version_id`s in Live status at the time of the inference in `prompt_version_ids_considered` field.
*/
export class InferenceCreateByPromptId {
    /**
    * The API consumer\'s internal user reference for metrics. It is also relayed to the provider as part of the request if the provider supports it (eg. OpenAI\'s user field).
    */
    'endUserId'?: string;
    /**
    * The API consumer\'s source for metrics (e.g. AndroidApp etc).
    */
    'source'?: string;
    /**
    * The API consumer\'s internal reference id to able to link references to their sessions.
    */
    'clientRefId'?: string;
    'templateArgs'?: { [key: string]: string; };
    'metadata'?: object;
    /**
    * Provider request timout in seconds. If not provided, then Prompton API\'s default timeout for the provider will be used (90sec or `DEFAULT_OPENAI_REQUEST_TIMEOUT_SECONDS` env var if provided).
    */
    'requestTimeout'?: number;
    'promptId': string;

    static discriminator: string | undefined = undefined;

    static attributeTypeMap: Array<{name: string, baseName: string, type: string}> = [
        {
            "name": "endUserId",
            "baseName": "end_user_id",
            "type": "string"
        },
        {
            "name": "source",
            "baseName": "source",
            "type": "string"
        },
        {
            "name": "clientRefId",
            "baseName": "client_ref_id",
            "type": "string"
        },
        {
            "name": "templateArgs",
            "baseName": "template_args",
            "type": "{ [key: string]: string; }"
        },
        {
            "name": "metadata",
            "baseName": "metadata",
            "type": "object"
        },
        {
            "name": "requestTimeout",
            "baseName": "request_timeout",
            "type": "number"
        },
        {
            "name": "promptId",
            "baseName": "prompt_id",
            "type": "string"
        }    ];

    static getAttributeTypeMap() {
        return InferenceCreateByPromptId.attributeTypeMap;
    }
}

